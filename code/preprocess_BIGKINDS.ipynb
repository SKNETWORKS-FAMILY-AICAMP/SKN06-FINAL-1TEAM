{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 컬럼 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 필요 컬럼: 일자, 언론사, 기고자, 제목, 키워드, 특성추출(가중치순 상위 50개), 본문, URL\n",
    "- 제거 대상 컬럼: 뉴스 식별자, 일자, 언론사, 기고자, 제목, 통합 분류1, 통합 분류2, 통합 분류3, 사건/사고 분류1, 사건/사고 분류2, <br> 사건/사고 분류3, 인물, 위치, 기관, 키워드, 특성추출(가중치순 상위 50개), 본문, URL, 분석제외 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 스크립트가 실행되는 폴더를 기준으로 'News' 폴더 설정\n",
    "BASE_DIR = os.getcwd()  # 현재 실행 중인 디렉토리 (어떤 기기에서도 동일 적용 가능)\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"News\")  # 'News' 폴더를 자동으로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata\\miniconda3\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "c:\\Users\\Playdata\\miniconda3\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "c:\\Users\\Playdata\\miniconda3\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일 로드 및 병합 완료.\n"
     ]
    }
   ],
   "source": [
    "# 전처리 할 파일 리스트\n",
    "file_list = [\n",
    "    os.path.join(DATA_DIR, \"BIGKINDSNews_20241103-20241202.xlsx\"),\n",
    "    os.path.join(DATA_DIR, \"BIGKINDSNews_20241203-20250102.xlsx\"),\n",
    "    os.path.join(DATA_DIR, \"BIGKINDSNews_20250103-20250203.xlsx\")\n",
    "]\n",
    "\n",
    "# 여러 개의 파일을 불러와 하나의 DataFrame으로 합치기\n",
    "df_list = []\n",
    "for file in file_list:\n",
    "    if os.path.exists(file):  # 파일이 존재하는지 확인\n",
    "        df_list.append(pd.read_excel(file))\n",
    "    else:\n",
    "        print(f\"파일 없음: {file}\")\n",
    "\n",
    "if not df_list:\n",
    "    raise FileNotFoundError(\"전처리할 파일이 존재하지 않습니다.\")\n",
    "\n",
    "df = pd.concat(df_list, ignore_index=True) # ignore_index=True: 기존 index 무시, 새로운 연속된 index 생성\n",
    "\n",
    "print(\"파일 로드 및 병합 완료.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 컬럼만 선택 후 df 생성\n",
    "columns_needed = ['일자', '언론사', '기고자', '제목', '키워드', '특성추출(가중치순 상위 50개)', '본문', 'URL']\n",
    "df = df[columns_needed]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 날짜 형식 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 문자열(YYYY-MM-DD) 형식을 datetime 형식으로 변환하여 날짜별 분석이 가능하도록 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '일자' 컬럼을 YYYY-MM-DD 형식으로 변환\n",
    "df['일자'] = df['일자'].astype(str).str[:8]  # YYYYMMDD 형식 유지\n",
    "df['일자'] = pd.to_datetime(df['일자'], format=\"%Y%m%d\", errors=\"coerce\")\n",
    "df['일자'] = df['일자'].dt.strftime(\"%Y-%m-%d\")  # 날짜만 남기기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 중복 데이터 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 기준: 제목, 본문\n",
    "- 중복 제거 후 인덱스 정리(재정렬)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(df):\n",
    "    \"\"\"\n",
    "    제목과 본문이 동일한 경우 중복으로 제거하고, 인덱스를 재정렬하는 함수\n",
    "\n",
    "    Parameters:\n",
    "        pd (pd.DataFrame): 데이터프레임\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: 중복 제거 및 인덱스 정리된 데이터프레임\n",
    "    \"\"\"\n",
    "    df = df.drop_duplicates(subset=['제목', '본문']).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# 중복 제거 적용\n",
    "df = remove_duplicates(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 결측값(NaN) 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '일자', '제목', '본문', 'URL' 중 하나라도 결측값이 있는 행 제거\n",
    "df.dropna(subset=['일자', '제목', '본문', 'URL'], inplace=True) # inplace=True: 원본 df 직접 수정\n",
    "\n",
    "# 제거 후 인덱스 재정렬\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "일자     0\n",
      "제목     0\n",
      "본문     0\n",
      "URL    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 결측값 개수 확인\n",
    "print(df[['일자', '제목', '본문', 'URL']].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 날짜 기준 최신순 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최신순 정렬 후 인덱스 재정렬\n",
    "df.sort_values(by='일자', ascending=False, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 텍스트 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 텍스트 데이터에서 불필요한 기호, 특수문자, 공백, 이모지 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 정제 함수 정의\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    # 연속된 공백 제거\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # 특수문자 제거(한글, 영어, 숫자만 남기기)\n",
    "    text = re.sub(r'[^\\w\\s가-힣]', '', text)\n",
    "    # 이모지 제거(유니코드 범위 내)\n",
    "    text = re.sub(r'[\\U00010000-\\U0010FFFF]', '', text)\n",
    "    return text.strip()\n",
    "\n",
    "# 제목과 본문 컬럼에 적용\n",
    "df['제목'] = df['제목'].apply(clean_text)\n",
    "df['본문'] = df['본문'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 키워드 및 특성추출 컬럼 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BIGKINDS 제공 데이터: 키워드, 특성추출(가중치순 상위 50개)\n",
    "- 리스트 형태의 컬럼을 KPF-BERT에서 활용하기 위해 쉼표(,)로 구분된 문자열로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_str(x):\n",
    "    if pd.isna(x):  # 결측값 처리\n",
    "        return \"\"\n",
    "    # 리스트일 경우 쉼표로 구분하여 문자열 변환\n",
    "    elif isinstance(x, list):\n",
    "        return ', '.join(map(str, x))\n",
    "    # 리스트가 아닐 경우 문자열 변환\n",
    "    else:\n",
    "        return str(x)\n",
    "\n",
    "df['키워드'] = df['키워드'].apply(list_to_str)\n",
    "df['특성추출(가중치순 상위 50개)'] = df['특성추출(가중치순 상위 50개)'].apply(list_to_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 최종 정리 및 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CSV 파일로 저장하여 KPF-BERT 모델 학습 및 추론에 사용할 수 있도록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장 경로 설정 및 압축 파일로 저장\n",
    "save_path = os.path.join(DATA_DIR, \"BIGKINDS_cleaned.csv\")\n",
    "\n",
    "# 디렉토리 존재 여부 확인 후 생성\n",
    "os.makedirs(DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일 저장 완료: c:\\Users\\Playdata\\Desktop\\final\\News\\BIGKINDS_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# 전처리된 데이터 저장\n",
    "df.to_csv(save_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"파일 저장 완료: {os.path.abspath(save_path)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
