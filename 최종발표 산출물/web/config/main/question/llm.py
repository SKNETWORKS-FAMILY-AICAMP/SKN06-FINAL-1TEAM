from langchain.agents import AgentType, initialize_agent
from langchain.tools import Tool
from langchain.chat_models import ChatOpenAI
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
from langchain.memory import ConversationBufferMemory
from dotenv import load_dotenv
from langchain.embeddings import OpenAIEmbeddings
import os, json, re,requests,pymysql,joblib
from rapidfuzz import process, fuzz
import pandas as pd
from main.question.title_mapping import find_best_matching_titles
from main.question.company_extraction import extract_company_and_info, get_candidate_companies, get_valid_company

def summarize_content(content: str, question: str,llm) -> str:
    """
    ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš©ì„ ì§ˆë¬¸ì— ë§ê²Œ ìš”ì•½í•˜ì—¬ ë°˜í™˜
    """
    summary_prompt = f"""
        ì‚¬ìš©ìì˜ ì§ˆë¬¸: "{question}"

        ë‹¹ì‹ ì€ ì‚¬ì—…ë³´ê³ ì„œë¥¼ ë¶„ì„í•˜ì—¬ í•„ìš”í•œ ë°ì´í„°ë¥¼ ì •í™•íˆ ì œê³µí•˜ëŠ” ì „ëµíŒ€ì…ë‹ˆë‹¤.
        ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë°ì´í„°ê°€ í…Œì´ë¸” í˜•íƒœë¡œ ì œê³µëœë‹¤ë©´, **ë°˜ë“œì‹œ í…Œì´ë¸”ì—ì„œ ë¨¼ì € ë°ì´í„°ë¥¼ ì¶”ì¶œ**í•˜ì„¸ìš”.

        ğŸ’¡ **ë‹µë³€ ë°©ì‹**
        1. ì§ˆë¬¸ì´ "ìµœê·¼ 3ë…„ê°„ ë§¤ì¶œ, ì˜ì—…ì´ìµ, ë‹¹ê¸°ìˆœì´ìµ"ê³¼ ê°™ì€ ì •ëŸ‰ì  ë°ì´í„° ìš”ì²­ì´ë¼ë©´:
        - í…Œì´ë¸”ì—ì„œ í•´ë‹¹ ë°ì´í„°ë¥¼ ì°¾ê³ , í‘œ í˜•íƒœ ê·¸ëŒ€ë¡œ ì œê³µí•˜ì„¸ìš”.
        - ë§Œì•½ í…Œì´ë¸”ì´ ì—†ë‹¤ë©´ ë³¸ë¬¸ì—ì„œ í•´ë‹¹ ìˆ˜ì¹˜ë¥¼ ì°¾ì•„ ì œê³µí•©ë‹ˆë‹¤.

        2. ì§ˆë¬¸ì´ "ë³„ë„ì¬ë¬´ì œí‘œ" ê¸°ì¤€ì¸ì§€ "ì—°ê²°ì¬ë¬´ì œí‘œ" ê¸°ì¤€ì¸ì§€ í™•ì¸í•˜ê³ , ë§ëŠ” ë°ì´í„°ë¥¼ ì„ íƒí•˜ì„¸ìš”.

        3. í•„ìš” ì—†ëŠ” ì„¤ëª… ì—†ì´ **ì •í™•í•œ ìˆ˜ì¹˜ ë°ì´í„°ë§Œ ì¶œë ¥**í•˜ì„¸ìš”.

        ğŸ“‘ **ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš©**:
        {content}

        ìœ„ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬, ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ê°„ê²°í•˜ê³  ì •í™•í•œ ë‹µë³€ì„ ìƒì„±í•˜ì„¸ìš”.
        """

    summary = llm.invoke(summary_prompt).content.strip()
    return summary

def aggregate_results(valid_results: list, query: str, company: str,llm) -> str:
    """
    ì—¬ëŸ¬ ë¬¸ì„œì—ì„œ ì¶”ì¶œëœ í•´ë‹¹ ê¸°ì—… ê´€ë ¨ ë°ì´í„°ë¥¼ ì „ëµíŒ€ ê´€ì ì—ì„œ ë¶„ì„í•˜ì—¬,
    í•´ë‹¹ ê¸°ì—…ì˜ '{query}'ì´(ê°€) ê¸°ì—… ê²½ìŸë ¥ ë° ì‹œì¥ ë‚´ ìœ„ì¹˜ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ê³¼
    í–¥í›„ ì „ëµ ìˆ˜ë¦½ì— ëŒ€í•œ ì‹œì‚¬ì ì„ ì¢…í•©í•˜ëŠ” ìµœì¢… ë³´ê³ ì„œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.
    
    --- ì‹œì‘ ---
    {combined_content}
    --- ë ---
    """
    combined_content = "\n".join(valid_results)
    final_prompt = f"""
        ### ğŸ“Œ {company}ì˜ {query} ê´€ë ¨ ì •ë³´ ê²€ìƒ‰ ê²°ê³¼

        ì•„ë˜ëŠ” {company}ì˜ ì‚¬ì—…ë³´ê³ ì„œì—ì„œ ì¶”ì¶œí•œ {query} ê´€ë ¨ ë°ì´í„°ì…ë‹ˆë‹¤.  
        ë¬¸ì„œì—ì„œ ì œê³µëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ **ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ ì •ë³´**ë¥¼ ì œê³µí•©ë‹ˆë‹¤.  
        ğŸ“Œ **ì£¼ì˜:** ë¶ˆí•„ìš”í•œ ì„¤ëª… ì—†ì´ **ì •í™•í•œ ì›ë³¸ ë°ì´í„°**ì™€ **í•µì‹¬ ë¶„ì„ ì •ë³´**ë¥¼ êµ¬ë¶„í•˜ì—¬ ì œê³µí•˜ì„¸ìš”.
        **ìš”êµ¬ì‚¬í•­:**
        - ì¤‘ìš”í•œ ë‚´ìš© ì™¸ ë¶€ê°€ì ì¸ ë‚´ìš©ì€ ìƒëµí•  ê²ƒ.
        - í‘œ ë°ì´í„°ëŠ” í•´ì„ í›„ ë°˜ë“œì‹œ ì¤„ ê¸€ í˜•ì‹ìœ¼ë¡œ í•˜ì—¬ ì œê³µí•  ê²ƒ.
        - ë‹µë³€ì€ 150ì ì´ë‚´ì˜ ê°„ê²°í•œ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•  ê²ƒ.
        - ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ë°˜ë“œì‹œ í¬í•¨í•  ê²ƒ.
        - ë°˜ë“œì‹œ ì •í™•í•œ ê°’ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ì„ ì‘ì„±í•  ê²ƒ.
        - ìµœì¢… ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ì¤„ ê¸€(plain text) í˜•ì‹ì´ì–´ì•¼ í•¨.
        - ì¡´ëŒ“ë§ í˜•ì‹ìœ¼ë¡œ ë‹µë³€ì„ ì¶œë ¥í•´ì•¼ í•¨.
        - ê¸ˆì•¡ ê´€ë ¨ ì •ë³´ê°€ ìˆì„ ê²½ìš°, í•´ë‹¹ ì •ë³´ì˜ ì‹œì (ì—°ë„, ì¼ì ë“±)ì„ ë°˜ë“œì‹œ ëª…ì‹œí•  ê²ƒ.


        ---
        ### **1ï¸âƒ£ ì›ë³¸ ë°ì´í„° (ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš©)**
        ğŸ“„ **ì¶œì²˜: ì‚¬ì—…ë³´ê³ ì„œ**
    --- ì‹œì‘ ---
    {combined_content}
    --- ë ---
    """
    final_summary = llm.invoke(final_prompt).content.strip()
    return final_summary


def process_question_query(query: str, collection, llm):
    """
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ì—¬ ìµœì ì˜ ê¸°ì—… ì •ë³´ë¥¼ ì°¾ì•„ ì œê³µí•˜ëŠ” í•¨ìˆ˜.
    """
    company_names, info = extract_company_and_info(query, llm)
    if not company_names or not info:
        return "âŒ ì§ˆë¬¸ì—ì„œ í•„ìš”í•œ ì •ë³´ë¥¼ ì •í™•íˆ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
    
    responses = ""

    for company in company_names:
        # âœ… ì˜¬ë°”ë¥¸ ê¸°ì—…ëª…ì„ ê²°ì •
        valid_company = get_valid_company(company, collection, llm)
        
        # âœ… íšŒì‚¬ì˜ íƒ€ì´í‹€ ëª©ë¡ ê²€ìƒ‰
        results = collection.get(where={"company": valid_company}, include=["metadatas"])
        if not results["metadatas"]:
            responses += f"âŒ {valid_company}ì˜ ì‚¬ì—…ë³´ê³ ì„œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
            continue

        company_titles = list(set([doc["title"] for doc in results["metadatas"] if "title" in doc]))
        
        # âœ… ê°€ì¥ ì ì ˆí•œ title ì„ íƒ
        best_titles = find_best_matching_titles(info, llm, company_titles, top_k=3)
        if not best_titles:
            responses += f"âŒ {valid_company}ì˜ ì ì ˆí•œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
            continue
        
        valid_results = []
        for title in best_titles:
            # âœ… í•´ë‹¹ title ê´€ë ¨ ë°ì´í„° ê²€ìƒ‰
            results = collection.similarity_search(
                f"{title}",
                filter={"$and": [{"company": valid_company}, {"title": title}]},
                k=1
            )

            if results:
                for doc in results:
                    source = doc.metadata.get("source", "ì¶œì²˜ì •ë³´ ì—†ìŒ")
                    summary = summarize_content(doc.page_content, query, llm)
                    if "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" not in summary:
                        valid_results.append(f"\nğŸ“„ ì¶œì²˜: {source}\n{summary}\n")
                        break
        
        # âœ… ìµœì¢… ì‘ë‹µ ìƒì„±
        if valid_results:
            aggregated_result = aggregate_results(valid_results, info, valid_company, llm)
            responses += aggregated_result
        else:
            responses += f"âŒ {valid_company}ì˜ {info} ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"

    return responses



def process_question_query(query: str, collection, llm):
    print("í•¨ìˆ˜")
    """
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë‹¨ê³„ë³„ë¡œ ì²˜ë¦¬í•˜ì—¬ ìµœì ì˜ ê¸°ì—… ì •ë³´(title)ë¥¼ ì°¾ì•„ ì œê³µí•˜ëŠ” í•¨ìˆ˜.
    """
    company_names, info = extract_company_and_info(query, llm)
    if not company_names or not info:
        return "âŒ ì§ˆë¬¸ì—ì„œ í•„ìš”í•œ ì •ë³´ë¥¼ ì •í™•íˆ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
    
    responses = ""
    for company in company_names:
        # ì˜¬ë°”ë¥¸ ê¸°ì—…ëª…ì„ ê²°ì • (DBì— ì—†ìœ¼ë©´ í›„ë³´ ëª©ë¡ì„ ë³´ì—¬ì£¼ê³  ì‚¬ìš©ìì—ê²Œ ì…ë ¥ë°›ìŒ)
        valid_company = get_valid_company(company, collection,llm)
        if "ìœ ì‚¬í•œ ê¸°ì—… ëª©ë¡" in valid_company:
            return f"âŒ {valid_company}\nê¸°ì—…ëª…ì„ ì •í™•íˆ ì…ë ¥í•´ì£¼ì„¸ìš”."
        print(f"\nğŸ” [STEP 2] {valid_company}ì˜ title ëª©ë¡ ê²€ìƒ‰ ì¤‘...")
        results = collection.get(
            where={"company": valid_company},
            include=["metadatas"],
        )
        if not results["metadatas"]:
            responses += f"âŒ {valid_company}ì˜ ì‚¬ì—…ë³´ê³ ì„œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
            print(f"ğŸš¨ {valid_company}ì˜ title ëª©ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            continue
        company_titles = list(set([doc["title"] for doc in results["metadatas"] if "title" in doc]))
        print(f"ğŸ“Œ [STEP 2 ê²°ê³¼] {valid_company}ì˜ title ëª©ë¡: {company_titles}")
        
        best_titles = find_best_matching_titles(info,llm, company_titles, top_k=3)
        if not best_titles:
            responses += f"âŒ {valid_company}ì˜ ì ì ˆí•œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
            continue
        print(f"ğŸ“Œ [STEP 3 ê²°ê³¼] ì„ íƒëœ title (ìš°ì„ ìˆœìœ„): {best_titles}")
        
        valid_results = []
        for title in best_titles:
            print(f"\nğŸ” [STEP 4] {valid_company} - '{title}' ë°ì´í„° ê²€ìƒ‰ ì¤‘...")
            results = collection.similarity_search(
    f"{title}",
    filter={"$and": [{"company": valid_company}, {"title": title}]},
    k=1
)
            if results:
                for doc in results:
                    source = doc.metadata.get("source", "ì¶œì²˜ì •ë³´ ì—†ìŒ")
                    summary = summarize_content(doc.page_content, query,llm)
                    if "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" not in summary:
                        valid_results.append(f"\nğŸ“„ ì¶œì²˜: {source}\n{summary}\n")
                        break
        if valid_results:
            aggregated_result = aggregate_results(valid_results, info, valid_company, llm)
            responses += aggregated_result
        else:
            responses += f"âŒ {valid_company}ì˜ {info} ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
    return responses