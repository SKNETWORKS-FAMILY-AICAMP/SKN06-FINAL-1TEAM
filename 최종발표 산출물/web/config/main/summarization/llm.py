from langchain.agents import AgentType, initialize_agent
from langchain.tools import Tool
from langchain.chat_models import ChatOpenAI
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
from langchain.memory import ConversationBufferMemory
from dotenv import load_dotenv
from langchain.embeddings import OpenAIEmbeddings
import os, json, re,requests,pymysql,joblib
from rapidfuzz import process, fuzz
import pandas as pd
from main.summarization.title_mapping import find_best_matching_titles
from main.summarization.company_extraction import extract_company_and_info, get_valid_company

def summarize_content(content: str, question: str, llm) -> str:
    """
    ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš©ì„ ì§ˆë¬¸ì— ë§ê²Œ ìš”ì•½í•˜ì—¬ ë°˜í™˜ (ì§ˆë¬¸ ìœ í˜•ë³„ ë§ì¶¤ ì‘ë‹µ ì ìš©)
    """

    # ì£¼ìš” í‚¤ì›Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜
    financial_keywords = ["ë§¤ì¶œ", "ì¬ë¬´", "ì‹¤ì ", "ì†ìµ", "ì´ìµ"]
    shareholder_keywords = ["ì£¼ì£¼", "ì§€ë¶„", "ì£¼ì‹"]
    credit_keywords = ["ì‹ ìš©", "ë“±ê¸‰", "ë¶€ì±„"]
    industry_keywords = ["ì£¼ìš” ì‚°ì—…", "ì‚°ì—… ë¶€ë¬¸", "ì‚°ì—… êµ¬ì¡°"]
    
    if any(keyword in question for keyword in industry_keywords):
        # "ì£¼ìš” ì‚°ì—…" ì§ˆë¬¸ì¼ ê²½ìš° â†’ ë§¤ì¶œ ë°ì´í„° ì œì™¸
        summary_prompt = f"""
        ì‚¬ìš©ìì˜ ì§ˆë¬¸: "{question}"
        
        ğŸ“Œ **ì „ëµíŒ€ ìš”ì•½ ì§€ì¹¨**
        - **ê²€ìƒ‰ëœ ë¬¸ì„œì—ì„œ ê´€ë ¨ëœ ì‚°ì—… ì •ë³´ë§Œ ì œê³µí•˜ì„¸ìš”.**
        - **ë§¤ì¶œ ë°ì´í„°(ìˆ«ì ì •ë³´)ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.**
        - **ê¸°ì—…ì´ ì†í•œ ì£¼ìš” ì‚°ì—…ì„ ê°„ëµí•˜ê²Œ ì •ë¦¬í•˜ì„¸ìš”.**
        
        ğŸ“‘ **ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš©**:
        --- ì‹œì‘ ---
        {content}
        --- ë ---

        ğŸ¯ **ìš”ì•½ëœ ê²°ê³¼**:
        """

    elif any(keyword in question for keyword in financial_keywords):
        # "ë§¤ì¶œ", "ì¬ë¬´" ê´€ë ¨ ì§ˆë¬¸ì¼ ê²½ìš° â†’ ì •ëŸ‰ì  ë°ì´í„° í¬í•¨
        summary_prompt = f"""
        ì‚¬ìš©ìì˜ ì§ˆë¬¸: "{question}"
        
        ğŸ“Œ **ì „ëµíŒ€ ìš”ì•½ ì§€ì¹¨**
        - **ê²€ìƒ‰ëœ ë¬¸ì„œì—ì„œ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì •ëŸ‰ì  ë°ì´í„°ë¥¼ í¬í•¨í•˜ì—¬ ìš”ì•½í•˜ì„¸ìš”.**
        - **í‘œ í˜•ì‹ì„ ìœ ì§€í•˜ì—¬ ìˆ«ì ë°ì´í„°ë¥¼ ë³´ê¸° ì‰½ê²Œ ì œê³µí•˜ì„¸ìš”.**
        - **ì—°ê²°ì¬ë¬´ì œí‘œ ë˜ëŠ” ë³„ë„ì¬ë¬´ì œí‘œì—ì„œ ì°¾ì€ ì •ë³´ì¸ì§€ ëª…í™•íˆ ëª…ì‹œí•˜ì„¸ìš”.**
        
        ğŸ“‘ **ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš©**:
        --- ì‹œì‘ ---
        {content}
        --- ë ---

        ğŸ¯ **ìš”ì•½ëœ ê²°ê³¼ (ì •ëŸ‰ì  ë°ì´í„° í¬í•¨)**:
        """

    elif any(keyword in question for keyword in shareholder_keywords):
        # "ì£¼ì£¼", "ì§€ë¶„" ê´€ë ¨ ì§ˆë¬¸ì¼ ê²½ìš° â†’ ê´€ë ¨ ì •ë³´ ìœ ì§€
        summary_prompt = f"""
        ì‚¬ìš©ìì˜ ì§ˆë¬¸: "{question}"
        
        ğŸ“Œ **ì „ëµíŒ€ ìš”ì•½ ì§€ì¹¨**
        - **ê²€ìƒ‰ëœ ë¬¸ì„œì—ì„œ ì£¼ì£¼ êµ¬ì„± ë° ì§€ë¶„ êµ¬ì¡° ê´€ë ¨ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.**
        - **ê°€ëŠ¥í•˜ë©´ ì£¼ìš” ì£¼ì£¼ì™€ ë³´ìœ  ë¹„ìœ¨ì„ í¬í•¨í•˜ì„¸ìš”.**
        
        ğŸ“‘ **ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš©**:
        --- ì‹œì‘ ---
        {content}
        --- ë ---

        ğŸ¯ **ìš”ì•½ëœ ê²°ê³¼ (ì£¼ì£¼ ì •ë³´ í¬í•¨)**:
        """

    elif any(keyword in question for keyword in credit_keywords):
        # "ì‹ ìš©", "ë“±ê¸‰", "ë¶€ì±„" ê´€ë ¨ ì§ˆë¬¸ì¼ ê²½ìš° â†’ ì‹ ìš© ì •ë³´ í¬í•¨
        summary_prompt = f"""
        ì‚¬ìš©ìì˜ ì§ˆë¬¸: "{question}"
        
        ğŸ“Œ **ì „ëµíŒ€ ìš”ì•½ ì§€ì¹¨**
        - **ê¸°ì—…ì˜ ì‹ ìš© ë“±ê¸‰, ë¶€ì±„ ë¹„ìœ¨ ë° ê¸ˆìœµ ì•ˆì •ì„± ê´€ë ¨ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.**
        - **ì—°ë„ë³„ ì‹ ìš© ë“±ê¸‰ ë³€ë™ì´ ìˆëŠ” ê²½ìš° í¬í•¨í•˜ì„¸ìš”.**
        
        ğŸ“‘ **ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš©**:
        --- ì‹œì‘ ---
        {content}
        --- ë ---

        ğŸ¯ **ìš”ì•½ëœ ê²°ê³¼ (ì‹ ìš© ì •ë³´ í¬í•¨)**:
        """

    else:
        # ì¼ë°˜ì ì¸ ì§ˆë¬¸ì˜ ê²½ìš° â†’ ê¸°ë³¸ì ì¸ ì •ë³´ ì œê³µ
        summary_prompt = f"""
        ì‚¬ìš©ìì˜ ì§ˆë¬¸: "{question}"
        
        ğŸ“Œ **ì „ëµíŒ€ ìš”ì•½ ì§€ì¹¨**
        - **ê²€ìƒ‰ëœ ë¬¸ì„œì—ì„œ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ ìˆëŠ” ì •ë³´ë¿ë§Œ ì•„ë‹ˆë¼, ì§ˆë¬¸ì˜ ì˜ë¯¸ì™€ ì—°ê²°ë  ìˆ˜ ìˆëŠ” ì •ë³´ë„ í¬í•¨í•˜ì„¸ìš”.**
        - **ì§ˆë¬¸ê³¼ ì™„ì „íˆ ì¼ì¹˜í•˜ëŠ” ì •ë³´ê°€ ì—†ì–´ë„, ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì—¬ ìš”ì•½í•˜ì„¸ìš”.**
        - **ì •ëŸ‰ì  ë°ì´í„°(ë§¤ì¶œ, ì˜ì—…ì´ìµ ë“±)ê°€ í¬í•¨ëœ ê²½ìš° ë°˜ë“œì‹œ í‘œ í˜•ì‹ì„ ìœ ì§€í•˜ì„¸ìš”.**
        
        ğŸ“‘ **ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš©**:
        --- ì‹œì‘ ---
        {content}
        --- ë ---

        ğŸ¯ **ìš”ì•½ëœ ê²°ê³¼**:
        """

    summary = llm.invoke(summary_prompt).content.strip()
    return summary

def aggregate_results(valid_results: list, query: str, company: str, llm) -> str:
    """
    ì—¬ëŸ¬ ë¬¸ì„œì—ì„œ ì¶”ì¶œëœ í•´ë‹¹ ê¸°ì—…ì˜ '{query}' ê´€ë ¨ ì •ë³´ë¥¼ ë³´ê¸° ì‰½ê²Œ ìš”ì•½í•˜ì—¬ ë°˜í™˜.
    """
    combined_content = "\n".join(valid_results)
    
    final_prompt = f"""
    ### ğŸ“Œ {company}ì˜ {query} ê´€ë ¨ ì‚¬ì—…ë³´ê³ ì„œ ìš”ì•½

    ğŸ“ **ìš”ì•½ ê¸°ì¤€**
    - **ì§ˆë¬¸ê³¼ ì™„ì „íˆ ì¼ì¹˜í•˜ëŠ” ì •ë³´ê°€ ì—†ë”ë¼ë„, ì˜ë¯¸ì ìœ¼ë¡œ ì—°ê²°ë  ìˆ˜ ìˆëŠ” ë°ì´í„°ë¥¼ í™œìš©í•˜ì„¸ìš”. ë‹¨ ì¼ì¹˜í•˜ëŠ” ì •ë³´ê°€ ìˆë‹¤ë©´ ê·¸ ì •ë³´ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤**
    - **ì‚¬ìš©ì ì§ˆë¬¸ ì˜ë„ì— ë§ê²Œ í•µì‹¬ ë‚´ìš©ë§Œ ë°˜í™˜**
    - **ì§ˆë¬¸ì´ ì¬ë¬´ì™€ ê´€ë ¨ëœ ì§ˆë¬¸ì´ë©´ **ì—°ê²°ì¬ë¬´ì œí‘œ**, **ì¬ë¬´ì œí‘œ(ë‹¨ì¼,ë³„ë„)** ì¤‘ ì–´ë–¤ ì •ë³´ë¥¼ ì œê³µ í•´ì¤¬ëŠ”ì§€ ì•Œë ¤ì¤˜ì•¼ í•©ë‹ˆë‹¤.
        ex) ì—°ê²°ì¬ë¬´ì œí‘œì—ì„œ ì°¾ì€ ì¬ë¬´ì •ë³´ì¸ì§€, ì¬ë¬´ì œí‘œ(ë‹¨ì¼,ë³„ë„)ì—ì„œ ì°¾ì€ ì •ë³´ì¸ì§€ êµ¬ë¶„ í•´ì¤˜ì•¼í•©ë‹ˆë‹¤.**
    - **ì§ˆë¬¸ì´ ë¹„ì¬ë¬´ì™€ ê´€ë ¨ëœ ì§ˆë¬¸ì´ë©´ ì–´ë–¤ **title**ì—ì„œ ì •ë³´ë¥¼ ì œê³µ í•´ì¤¬ëŠ”ì§€ ì•Œë ¤ì¤˜ì•¼í•©ë‹ˆë‹¤.
        ex_íšŒì‚¬ì˜ ê°œìš”ì—ì„œ ì°¾ì€ ì‹ ìš©ì •ë³´ì¸ì§€, ì‚¬ì—…ì˜ ê°œìš”ì—ì„œ ì°¾ì€ ì£¼ìš”ì‚°ì—… ì •ë³´ì¸ì§€ êµ¬ë¶„ í•´ì¤˜ì•¼í•©ë‹ˆë‹¤.

    ğŸ“Š **1.1ï¸âƒ£ ê²€ìƒ‰ëœ ë¬¸ì„œ ë¶„ì„**
    --- ì‹œì‘ ---
    {combined_content}
    --- ë ---

    âœ… **ìµœì¢… ìš”ì•½**
    - **ë¶„ì„ëœ ë‚´ìš©ì„ í† ëŒ€ë¡œ ê°„ëµí•˜ê²Œ í•µì‹¬ ì •ë³´ë§Œ ì œê³µ **
    """
    
    final_summary = llm.invoke(final_prompt).content.strip()
    return final_summary






def process_summarization_query(query: str, collection, llm):
    print("í•¨ìˆ˜")
    """
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë‹¨ê³„ë³„ë¡œ ì²˜ë¦¬í•˜ì—¬ ìµœì ì˜ ê¸°ì—… ì •ë³´(title)ë¥¼ ì°¾ì•„ ì œê³µí•˜ëŠ” í•¨ìˆ˜.
    """
    company_names, info = extract_company_and_info(query, llm)
    if not company_names or not info:
        return "âŒ ì§ˆë¬¸ì—ì„œ í•„ìš”í•œ ì •ë³´ë¥¼ ì •í™•íˆ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
    
    responses = ""
    for company in company_names:
        # ì˜¬ë°”ë¥¸ ê¸°ì—…ëª…ì„ ê²°ì • (DBì— ì—†ìœ¼ë©´ í›„ë³´ ëª©ë¡ì„ ë³´ì—¬ì£¼ê³  ì‚¬ìš©ìì—ê²Œ ì…ë ¥ë°›ìŒ)
        valid_company = get_valid_company(company, collection,llm)
        if "ìœ ì‚¬í•œ ê¸°ì—… ëª©ë¡" in valid_company:
            return f"âŒ {valid_company}\nê¸°ì—…ëª…ì„ ì •í™•íˆ ì…ë ¥í•´ì£¼ì„¸ìš”."
        print(f"\nğŸ” [STEP 2] {valid_company}ì˜ title ëª©ë¡ ê²€ìƒ‰ ì¤‘...")
        results = collection.get(
            where={"company": valid_company},
            include=["metadatas"],
        )
        if not results["metadatas"]:
            responses += f"âŒ {valid_company}ì˜ ì‚¬ì—…ë³´ê³ ì„œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
            print(f"ğŸš¨ {valid_company}ì˜ title ëª©ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            continue
        company_titles = list(set([doc["title"] for doc in results["metadatas"] if "title" in doc]))
        print(f"ğŸ“Œ [STEP 2 ê²°ê³¼] {valid_company}ì˜ title ëª©ë¡: {company_titles}")
        
        best_titles = find_best_matching_titles(info,llm, company_titles, top_k=3)
        if not best_titles:
            responses += f"âŒ {valid_company}ì˜ ì ì ˆí•œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
            continue
        print(f"ğŸ“Œ [STEP 3 ê²°ê³¼] ì„ íƒëœ title (ìš°ì„ ìˆœìœ„): {best_titles}")
        
        valid_results = []
        for title in best_titles:
            print(f"\nğŸ” [STEP 4] {valid_company} - '{title}' ë°ì´í„° ê²€ìƒ‰ ì¤‘...")
            results = collection.similarity_search(
    f"{title}",
    filter={"$and": [{"company": valid_company}, {"title": title}]},
    k=5
)
            if results:
                for doc in results:
                    source = doc.metadata.get("source", "ì¶œì²˜ì •ë³´ ì—†ìŒ")
                    summary = summarize_content(doc.page_content, query,llm)
                    if "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" not in summary:
                        valid_results.append(f"\nğŸ“„ ì¶œì²˜: {source}\n{summary}\n")
                        break
        if valid_results:
            aggregated_result = aggregate_results(valid_results, info, valid_company, llm)
            responses += aggregated_result
        else:
            responses += f"âŒ {valid_company}ì˜ {info} ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
    return responses