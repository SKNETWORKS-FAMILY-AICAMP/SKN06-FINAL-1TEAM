from langchain.agents import AgentType, initialize_agent
from langchain.tools import Tool
from langchain.chat_models import ChatOpenAI
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
from langchain.memory import ConversationBufferMemory
from langchain.embeddings import OpenAIEmbeddings
from main.prediction.llm import interactive_forecast
from main.question.llm import process_question_query
from main.summarization.llm import process_summarization_query
import os
# OpenAI ëª¨ë¸ ì´ˆê¸°í™” (GPT-4o-mini rì‚¬ìš©)
api_key = os.getenv("OPEN_API_KEY")

# ì§ˆë¬¸ ë¶„ë¥˜ í•¨ìˆ˜
def classify_question(query,llm):
    prompt = f"""
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ "ì˜ˆì¸¡", "ê²€ìƒ‰", "ìš”ì•½" ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.
    ë°˜ë“œì‹œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”: ì˜ˆì¸¡ / ê²€ìƒ‰ / ìš”ì•½ (ê·¸ ì™¸ ë‹¨ì–´ í¬í•¨ ê¸ˆì§€)

    ì§ˆë¬¸: "{query}"
    ì¶œë ¥:
    """
    response = llm.invoke(prompt).content.strip()
    print(f"ğŸ” classify_question ê²°ê³¼: '{response}'")
    return response

# ì§ˆë¬¸ ìœ í˜•ë³„ ì²˜ë¦¬ í•¨ìˆ˜
def process_question(query,collection, llm):
    return process_question_query(query,collection, llm)

def process_per(query,llm):
    return interactive_forecast(query,llm)

def process_summarization(query,collection,llm):
    return process_summarization_query(query,collection,llm)

# Tool ì •ì˜
tools = [
    Tool(
        name="Process Search Question",
        func=process_question,
        description="ì‚¬ìš©ìê°€ ê²€ìƒ‰ì„ ìš”ì²­í•  ê²½ìš° ì‹¤í–‰ë˜ëŠ” ë„êµ¬"
    ),
    Tool(
        name="Process Predict Question",
        func=process_per,
        description="ì‚¬ìš©ìê°€ ì˜ˆì¸¡ì„ ìš”ì²­í•  ê²½ìš° ì‹¤í–‰ë˜ëŠ” ë„êµ¬"
    ),
    Tool(
        name="Process Summarization Question",
        func=process_summarization,
        description="ì‚¬ìš©ìê°€ ìš”ì•½ì„ ìš”ì²­í•  ê²½ìš° ì‹¤í–‰ë˜ëŠ” ë„êµ¬"
    ),
]





# ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
def agent_reset(llm):
    memory = ConversationBufferMemory(memory_key="chat_history")
    agent = initialize_agent(
        tools=tools,
        llm=llm,
        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
        verbose=True,
        memory=memory
    )


# ì‚¬ìš©ì ì§ˆë¬¸ ì²˜ë¦¬ í•¨ìˆ˜
def handle_user_query(query,collection, llm):
    category = classify_question(query,llm).strip()
    print(f"ğŸ” ì§ˆë¬¸ ìœ í˜•: '{category}'")  # ì‘ë‹µ ì¶œë ¥

    if category == "ê²€ìƒ‰":
        print("ğŸ” ê²€ìƒ‰ ì‹¤í–‰:", query)  # ì‹¤í–‰ ì—¬ë¶€ í™•ì¸
        response = process_question(query, collection, llm)  # ì˜¬ë°”ë¥¸ í•¨ìˆ˜ ì‹¤í–‰
        return response
    elif category == "ì˜ˆì¸¡":
        print("ğŸ”® ì˜ˆì¸¡ ì‹¤í–‰:", query)
        response = process_per(query,llm)
        return response
    elif category == "ìš”ì•½":
        print("ğŸ“ ìš”ì•½ ì‹¤í–‰:", query)
        return process_summarization(query, collection, llm)
    else:
        return "âš ï¸ ì§ˆë¬¸ ìœ í˜•ì„ ë¶„ë¥˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    


